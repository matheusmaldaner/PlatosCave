{
  "nodes": [
    {
      "id": 0,
      "text": "A systematic comparison of commonly used feature selection methods provides guidance to select appropriate methods for improving text classification accuracy and efficiency",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3
      ]
    },
    {
      "id": 1,
      "text": "High-dimensional text data contain many noisy terms that hurt text classification performance, and feature selection (FS) reduces noise by selecting informative terms",
      "role": "Context",
      "parents": [
        0
      ],
      "children": [
        4
      ]
    },
    {
      "id": 2,
      "text": "Few recent studies provide systematic performance comparisons of a wide range of typical FS methods across diverse text domains",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        5
      ]
    },
    {
      "id": 3,
      "text": "We conducted comparative experiments using twenty typical FS methods on four benchmark datasets and evaluated classification accuracy with decision trees using 10-fold cross validation",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        6,
        7,
        8
      ]
    },
    {
      "id": 4,
      "text": "Feature selection increases the proportion of informative terms and decreases the proportion of noisy terms, thereby mitigating negative effects on classifier training",
      "role": "Claim",
      "parents": [
        1
      ],
      "children": null
    },
    {
      "id": 5,
      "text": "A systematic comparison covering many typical FS methods and reliable datasets can produce more persuasive guidelines for researchers and applications",
      "role": "Claim",
      "parents": [
        2
      ],
      "children": null
    },
    {
      "id": 6,
      "text": "Datasets used: CARR (car reviews), COMD (Brazilian company descriptions), IMDB (movie reviews), KDCN (Turkish news), all from UCI repository and spanning multiple domains",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 7,
      "text": "Classifier and evaluation: Decision tree classifier chosen; classification accuracy measured; 10-fold cross validation applied",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 8,
      "text": "The twenty FS methods compared include supervised measures (IG, ECE, MI variants, GI, IGI, CHI variants, OR variants, MOR, MC-OR) and unsupervised measures (DF, TF, MM, AMGM, TV, MAD, TVQ)",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 9,
      "text": "Experimental result: MOR and MC-OR achieved the highest classification accuracy among all compared FS methods",
      "role": "Result",
      "parents": [
        3
      ],
      "children": [
        11,
        12
      ]
    },
    {
      "id": 10,
      "text": "Experimental result: IGI performed nearly as well as MOR and MC-OR while having a simpler formula and lower implementation complexity",
      "role": "Result",
      "parents": [
        3
      ],
      "children": [
        12
      ]
    },
    {
      "id": 11,
      "text": "Experimental result: Unsupervised methods TV, TVQ, TF, and DF achieved relatively good accuracy and are preferable when computational efficiency is prioritized",
      "role": "Result",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 12,
      "text": "Experimental result: IG, GI, and MI variants produced the worst classification accuracies; ECE performed well generally but poorly when very few features were selected; AMGM, MM, MAD showed unstable results across datasets",
      "role": "Result",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 13,
      "text": "Conclusion: MOR and MC-OR are recommended as best choices for text classification accuracy, though they are computationally complex",
      "role": "Conclusion",
      "parents": [
        9
      ],
      "children": [
        14
      ]
    },
    {
      "id": 14,
      "text": "Conclusion: IGI is recommended as an ideal candidate balancing high accuracy and simpler implementation; TV, TVQ, TF, DF are recommended when efficiency is a priority",
      "role": "Conclusion",
      "parents": [
        10,
        11
      ],
      "children": null
    }
  ]
}