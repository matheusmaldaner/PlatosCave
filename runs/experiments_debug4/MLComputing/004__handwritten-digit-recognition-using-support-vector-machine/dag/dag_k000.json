{
  "nodes": [
    {
      "id": 0,
      "text": "Using Support Vector Machines (SVM) at the segment classification level and integrating SVM with HMM will improve handwritten numeral recognition compared to existing NN/HMM or HMM systems",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        3,
        6,
        8,
        10
      ]
    },
    {
      "id": 1,
      "text": "SVM provides better global discrimination and generalization than local elastic models (e.g., HMM) or neural networks for classifying variable and distorted handwriting segments",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        2,
        6
      ]
    },
    {
      "id": 2,
      "text": "Handwritten patterns show huge variability and distortions; HMMs based on local observations are sensitive to distortions and length variability while SVMs estimate global correlations",
      "role": "Context",
      "parents": [
        1
      ],
      "children": null
    },
    {
      "id": 3,
      "text": "Feature extraction uses moment invariants and affine moment invariants producing 18 features, and thinning yields additional features used in classification",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        13
      ]
    },
    {
      "id": 4,
      "text": "Datasets used include UCI Optdigits (8x8 preprocessed form), a collected Assamese handwritten set of 8235 samples, and IRONOFF and UNIPEN databases",
      "role": "Method",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 5,
      "text": "SVM multiclass classification is implemented via one-versus-rest scheme and supports nonlinear mapping via kernel functions",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        15
      ]
    },
    {
      "id": 6,
      "text": "Experimental results on isolated character datasets show SVM recognition rates higher than HMM across the three evaluated databases",
      "role": "Result",
      "parents": [
        0,
        1
      ],
      "children": [
        7,
        8
      ]
    },
    {
      "id": 7,
      "text": "A test application analysis reported 98% correct identification on a disjoint testing set using the discriminant classifier applied to processed Optdigits entries",
      "role": "Evidence",
      "parents": [
        6
      ],
      "children": null
    },
    {
      "id": 8,
      "text": "SVM models require significantly more memory than HMM because storage scales with number of support vectors times number of features (e.g., 350 features per example)",
      "role": "Claim",
      "parents": [
        0,
        6
      ],
      "children": [
        9,
        12
      ]
    },
    {
      "id": 9,
      "text": "Storage requirements for SVM can be reduced by storing compact original online signals with pen-up/pen-down status and expanding the model dynamically during recognition",
      "role": "Claim",
      "parents": [
        8
      ],
      "children": null
    },
    {
      "id": 10,
      "text": "Integrating SVM character recognizer into an HMM-based word recognition framework is being implemented and is expected to improve hybrid word recognition performance",
      "role": "Conclusion",
      "parents": [
        0,
        6
      ],
      "children": [
        11
      ]
    },
    {
      "id": 11,
      "text": "This expectation relies on the assumption that improved character segment discrimination by SVM will translate into higher word-level recognition when combined with HMM word search",
      "role": "Assumption",
      "parents": [
        10
      ],
      "children": null
    },
    {
      "id": 12,
      "text": "A limitation of the proposed SVM approach is large free parameter storage compared to HMM; HMM benefits from weight sharing and smaller memory footprint",
      "role": "Limitation",
      "parents": [
        8
      ],
      "children": null
    },
    {
      "id": 13,
      "text": "In some experiments each example produced 350 input feature values by extracting seven local features per resampled spatial point from online signals",
      "role": "Method",
      "parents": [
        3
      ],
      "children": [
        5,
        15
      ]
    },
    {
      "id": 15,
      "text": "SVM training used kernel methods; for experiments an RBF kernel was selected with hyperparameters chosen by grid search, with C = 8 selected for final models",
      "role": "Result",
      "parents": [
        5,
        13
      ],
      "children": null
    }
  ]
}