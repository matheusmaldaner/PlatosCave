{
  "nodes": [
    {
      "id": 0,
      "text": "A comprehensive review can characterize the state of machine learning interpretability research, focusing on societal impact, developed methods, and metrics, and identify future directions",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        9
      ]
    },
    {
      "id": 1,
      "text": "Machine learning systems are increasingly ubiquitous, deployed in everyday products and high-stakes regulated domains, creating strong societal impact and demand for interpretability",
      "role": "Context",
      "parents": [
        0
      ],
      "children": [
        5
      ]
    },
    {
      "id": 2,
      "text": "Interpretability is needed because predictive accuracy alone is an incomplete task specification for many real-world problems, especially safety, ethics, mismatched objectives, and multi-objective trade-offs",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        5,
        6
      ]
    },
    {
      "id": 3,
      "text": "Explainable AI (XAI) has emerged to produce interpretable models and post-hoc explanation methods that preserve predictive performance while enabling human understanding, trust, auditability, and compliance with regulation such as GDPR",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        6,
        4
      ]
    },
    {
      "id": 4,
      "text": "This survey conducts a structured literature review and taxonomy of interpretability methods, scopes, properties, human-centered explanation characteristics, and evaluation approaches",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        7,
        8
      ]
    },
    {
      "id": 5,
      "text": "Societal concerns evidenced include biased and harmful outcomes in criminal justice and other domains (e.g., COMPAS) and regulatory responses and public initiatives calling for transparency and explainability",
      "role": "Evidence",
      "parents": [
        1,
        2
      ],
      "children": null
    },
    {
      "id": 6,
      "text": "Interpretability supports desiderata such as fairness, privacy, reliability/robustness, causality (causability), and trust, and enables auditing, debugging, safety, and social acceptance",
      "role": "Claim",
      "parents": [
        2,
        3
      ],
      "children": [
        5
      ]
    },
    {
      "id": 7,
      "text": "Taxonomy: methods classified by timing (pre-model, in-model, post-model), nature (intrinsic vs post-hoc), model dependence (model-specific vs model-agnostic), and scope (algorithm transparency, global, local)",
      "role": "Result",
      "parents": [
        4
      ],
      "children": [
        10
      ]
    },
    {
      "id": 8,
      "text": "Explanations are produced in different forms (feature summaries, model internals, data points, surrogate models) and should satisfy human-oriented properties such as contrastiveness, selectivity, social context, focus on abnormalities, truthfulness and consistency with prior beliefs",
      "role": "Result",
      "parents": [
        4
      ],
      "children": [
        10
      ]
    },
    {
      "id": 9,
      "text": "There is no consensus on how to assess explanation quality; assessment requires metrics, proxies, or human-grounded experiments and must be contextualized by domain, task, and audience",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        11,
        12
      ]
    },
    {
      "id": 10,
      "text": "Properties and desiderata for explanations and methods are enumerated: accuracy/fidelity, consistency, stability, comprehensibility, certainty, importance, novelty, representativeness, expressive power, translucency, portability, and algorithmic complexity",
      "role": "Result",
      "parents": [
        7,
        8
      ],
      "children": [
        9
      ]
    },
    {
      "id": 11,
      "text": "Existing quantitative and axiomatic assessment proposals include integrated gradients axioms (sensitivity, implementation invariance), explanation-consistency axioms (identity, separability, stability), and task proxies such as completeness, correctness, and compactness",
      "role": "Evidence",
      "parents": [
        9
      ],
      "children": [
        12
      ]
    },
    {
      "id": 12,
      "text": "Current research emphasis has been on producing new explanation methods rather than rigorous, comparative assessment; only limited work proposes metrics or frameworks for evaluation",
      "role": "Claim",
      "parents": [
        9,
        11
      ],
      "children": [
        13,
        14
      ]
    },
    {
      "id": 13,
      "text": "Recommendation: advance interdisciplinary, application-grounded evaluation, develop model-agnostic frameworks and context-aware metrics, and prioritize assessment and comparison of methods over proliferating new unvalidated techniques",
      "role": "Conclusion",
      "parents": [
        12
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "Limitation: interpretability is subjective and domain-specific, making universal formalization difficult; thus assessments must be contextualized and may require human experiments for validity",
      "role": "Limitation",
      "parents": [
        12
      ],
      "children": null
    }
  ]
}