{
  "nodes": [
    {
      "id": 0,
      "text": "Bagging reduces classification error; this paper tests two Bayesian explanations for why bagging works",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3
      ]
    },
    {
      "id": 1,
      "text": "Hypothesis 1: Bagging works because it approximates Bayesian model averaging (sampling high-posterior models and averaging them)",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        4,
        5,
        6
      ]
    },
    {
      "id": 2,
      "text": "Hypothesis 2: Bagging works because it effectively changes the model space and/or implicit prior of the learner, shifting probability to models that better fit the domain (e.g., counteracts simplicity bias)",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        7,
        8,
        12
      ]
    },
    {
      "id": 3,
      "text": "Method: Empirical evaluation using C4.5 decision-tree learner, 26 UCI datasets, bagging with m bootstrap replicates, error measured by ten-fold cross-validation and additional meta-learning experiments",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        4,
        7,
        9
      ]
    },
    {
      "id": 4,
      "text": "Test of Hypothesis 1a: Compare bagging (uniform vote) with Bayesian model averaging weighting models by posterior under uniform and region noise models",
      "role": "Method",
      "parents": [
        1,
        3
      ],
      "children": [
        5
      ]
    },
    {
      "id": 5,
      "text": "Result: Bayesian model averaging with uniform prior and posterior weighting performed worse than bagging on a large majority of datasets (e.g., 19 of 25) and worse on average; results stable across m=10,25,50,100",
      "role": "Result",
      "parents": [
        4
      ],
      "children": [
        6
      ]
    },
    {
      "id": 6,
      "text": "Conclusion: Empirical evidence contradicts Hypothesis 1 that bagging works by approximating Bayesian model averaging with an uninformed prior",
      "role": "Conclusion",
      "parents": [
        1,
        5
      ],
      "children": null
    },
    {
      "id": 7,
      "text": "Test of Hypothesis 2a: Hypothesis that bagging counteracts an inappropriate simplicity bias by shifting probability to more complex models; evaluate complexity of bagged ensemble via meta-learning",
      "role": "Method",
      "parents": [
        2,
        3
      ],
      "children": [
        8,
        9,
        10
      ]
    },
    {
      "id": 8,
      "text": "Method detail: Meta-learning procedure â€” generate many random examples labeled by the bagged ensemble and learn a single tree/rule set from them using the base learner to compare complexity under same simplicity bias",
      "role": "Method",
      "parents": [
        7
      ],
      "children": [
        9
      ]
    },
    {
      "id": 9,
      "text": "Result: In 22 datasets where bagging improved on single rule set, meta-learning produced a rule set with lower error in all but four, with over 99% confidence; meta-learning error reductions averaged 60% of bagging's",
      "role": "Result",
      "parents": [
        7,
        8,
        3
      ],
      "children": [
        10,
        11
      ]
    },
    {
      "id": 10,
      "text": "Result: Meta-learned rule sets were more complex than directly learned ones in every case, typically by factor 2 to 6; complexity inversely correlated with error (higher complexity, lower error)",
      "role": "Result",
      "parents": [
        9
      ],
      "children": [
        11
      ]
    },
    {
      "id": 11,
      "text": "Conclusion: Empirical evidence supports that bagging works at least in part by effectively changing the implicit prior/model space to favor more complex models, counteracting simplicity bias",
      "role": "Conclusion",
      "parents": [
        2,
        9,
        10
      ],
      "children": [
        13
      ]
    },
    {
      "id": 12,
      "text": "Evidence against Hypothesis 1b: Correlation analysis shows in-bag error and out-of-bag error are usually positively correlated, so a prior favoring higher training error (to cancel likelihood) would hurt performance and contradict bagging's effect",
      "role": "Evidence",
      "parents": [
        1
      ],
      "children": [
        6
      ]
    },
    {
      "id": 13,
      "text": "Final conclusion: Bagging's success is unlikely due to approximating Bayesian model averaging with uninformed priors; it plausibly succeeds by correcting an overly-strong simplicity bias in learners like decision trees",
      "role": "Conclusion",
      "parents": [
        6,
        11
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "Assumption: The paper assumes relevance only for (learner, domain) pairs where bagging actually reduces error and treats learners as producing a single model with implicit bias",
      "role": "Assumption",
      "parents": [
        3
      ],
      "children": null
    }
  ]
}