{
  "nodes": [
    {
      "id": 0,
      "text": "Bagging reduces a classification learner's error rate; this paper tests two Bayesian-based explanations for why bagging works: (1) it approximates Bayesian model averaging, and (2) it effectively changes the learner's model space or implicit prior to better fit the domain",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        11
      ]
    },
    {
      "id": 1,
      "text": "Hypothesis 1: Bagging works because it approximates the optimal Bayesian model averaging procedure (averaging models weighted by posterior) more closely than selecting a single best model",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        4,
        5
      ]
    },
    {
      "id": 2,
      "text": "Hypothesis 2: Bagging works because it changes the effective model space and/or implicit prior (for example by counteracting an excessive simplicity bias) to one that better fits the domain",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        7,
        8,
        9
      ]
    },
    {
      "id": 3,
      "text": "Method: Empirical evaluation using C4.5 decision-tree learner on 26 UCI datasets, bootstrap sampling with m replicates (m varied: 10, 25, 50, 100), and ten-fold cross-validation to measure error",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        4,
        5,
        7
      ]
    },
    {
      "id": 4,
      "text": "Evidence against Hypothesis 1 (variant la): Weighting bagged models by Bayesian posterior approximations (using uniform class-noise and region-based likelihoods) performed worse than uniform voting (bagging) on a large majority of datasets (e.g., 19 of 25) and on average",
      "role": "Evidence",
      "parents": [
        1,
        3
      ],
      "children": null
    },
    {
      "id": 5,
      "text": "Evidence against Hypothesis 1 (variant lb): Correlation between in-bag (training) error and out-of-bag error is positive in most datasets (positive in 22 of 26, >0.5 in half of those), so a prior favoring higher training error would not explain bagging's error reduction",
      "role": "Evidence",
      "parents": [
        1,
        3
      ],
      "children": null
    },
    {
      "id": 6,
      "text": "Assumption: The hypotheses are evaluated for learner-domain pairs where the base learner outputs a single model and where bagging actually reduces error",
      "role": "Assumption",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 7,
      "text": "Method for testing Hypothesis 2 (meta-learning): Create a large synthetic training set labeled by the bagged ensemble, then induce a single decision-tree or rule set from that labeled data using the same base learner (C4.5) to approximate the simplest single-model representing the ensemble",
      "role": "Method",
      "parents": [
        2,
        3
      ],
      "children": [
        8,
        9
      ]
    },
    {
      "id": 8,
      "text": "Evidence supporting Hypothesis 2: In 22 databases where bagging improved over the single rule set, meta-learning also produced a rule set with lower error in all but four cases; reductions were significant (sign and Wilcoxon tests) and averaged about 60% of bagging's error reduction",
      "role": "Evidence",
      "parents": [
        2,
        7
      ],
      "children": null
    },
    {
      "id": 9,
      "text": "Evidence supporting Hypothesis 2 (complexity shift): Meta-learned rule sets were more complex than directly-learned ones in every case (typically 2x to 6x more antecedents/consequents), and error and complexity were inversely correlated (higher complexity associated with lower error)",
      "role": "Evidence",
      "parents": [
        2,
        7
      ],
      "children": null
    },
    {
      "id": 10,
      "text": "Result: Uniform voting over bootstrap-sampled models (bagging) empirically outperforms simple Bayesian posterior-weighted approximations for the tested learner and datasets",
      "role": "Result",
      "parents": [
        3,
        4
      ],
      "children": [
        12
      ]
    },
    {
      "id": 11,
      "text": "Limitation: Conclusions apply primarily to the tested setting (C4.5 decision trees, 26 UCI datasets, and cases where bagging reduces error); results may not generalize to all learners or domains",
      "role": "Limitation",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 12,
      "text": "Conclusion: Empirical evidence makes it unlikely that bagging's success is due to approximating Bayesian model averaging; it is plausible that bagging instead works at least in part by correcting an overly-strong simplicity bias of the underlying learner, shifting implicit prior/model-space toward more complex models",
      "role": "Conclusion",
      "parents": [
        0,
        2,
        8,
        9,
        10
      ],
      "children": null
    }
  ]
}