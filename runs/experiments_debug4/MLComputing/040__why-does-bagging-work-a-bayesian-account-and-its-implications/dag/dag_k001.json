{
  "nodes": [
    {
      "id": 0,
      "text": "Bagging reduces a classification learner's error rate and the paper aims to determine why it works",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3
      ]
    },
    {
      "id": 1,
      "text": "Hypothesis 1: Bagging works because it approximates Bayesian model averaging (voting among models weighted by posterior probabilities)",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        4,
        5,
        6
      ]
    },
    {
      "id": 2,
      "text": "Hypothesis 2: Bagging works because it effectively changes the learner's model space and/or implicit prior, reducing an inappropriate simplicity bias",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        7,
        8,
        12
      ]
    },
    {
      "id": 3,
      "text": "Method: Empirical evaluation using C4.5 decision-tree learner (with RULES post-processor) on 26 UCI datasets, bagging with m bootstrap replicates and ten-fold cross-validation",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        4,
        7,
        9
      ]
    },
    {
      "id": 4,
      "text": "Test of Hypothesis 1a: compare bagging (uniform voting) to Bayesian model averaging using posterior-weighted voting under uniform noise and region-based likelihoods, with m in {10,25,50,100}",
      "role": "Method",
      "parents": [
        1,
        3
      ],
      "children": [
        5
      ]
    },
    {
      "id": 5,
      "text": "Result: Posterior-weighted model averaging with a uniform prior consistently performed worse than uniform voting bagging on a large majority of datasets (e.g., 19 of 25 with m=25), across m values tested",
      "role": "Result",
      "parents": [
        4
      ],
      "children": [
        6
      ]
    },
    {
      "id": 6,
      "text": "Conclusion: Empirical evidence contradicts Hypothesis 1 (bagging as approximation to Bayesian model averaging) and specifically contradicts Hypothesis 1a",
      "role": "Conclusion",
      "parents": [
        1,
        5
      ],
      "children": null
    },
    {
      "id": 7,
      "text": "Test of Hypothesis 1b: consider whether bagging implicitly assumes a prior that cancels likelihood (favoring models with higher training error), tested via correlation between in-bag and out-of-bag error",
      "role": "Method",
      "parents": [
        1,
        3
      ],
      "children": [
        8
      ]
    },
    {
      "id": 8,
      "text": "Evidence: Models are almost always overfitted (lower in-bag than out-of-bag error), but in-bag and out-of-bag errors are positively correlated in 22 of 26 datasets (correlation >0.5 in half of those), i.e., lower in-bag error usually accompanies lower out-of-bag error",
      "role": "Evidence",
      "parents": [
        7
      ],
      "children": [
        9
      ]
    },
    {
      "id": 9,
      "text": "Inference: Because lower in-bag error generally predicts lower out-of-bag error, an error-favoring prior (penalizing low training error) would increase test error, contradicting Hypothesis 1b",
      "role": "Claim",
      "parents": [
        8
      ],
      "children": [
        6
      ]
    },
    {
      "id": 10,
      "text": "Method for testing Hypothesis 2: Meta-learning by generating many random examples labeled by the bagged ensemble and training C4.5 on that synthetic set to produce a single model approximating the ensemble's decision regions",
      "role": "Method",
      "parents": [
        2,
        3
      ],
      "children": [
        11,
        13
      ]
    },
    {
      "id": 11,
      "text": "Result: In 22 databases where bagging improved over single rule set, meta-learned rule set also produced lower error in all but four, with over 99% confidence; meta-learning captured on average 60% of bagging's error reduction",
      "role": "Result",
      "parents": [
        10
      ],
      "children": [
        12
      ]
    },
    {
      "id": 12,
      "text": "Evidence: The meta-learned rule sets are more complex than direct learner rule sets in every case (typically 2 to 6 times more complex), and error and complexity are inversely correlated during meta-learning",
      "role": "Evidence",
      "parents": [
        11,
        2
      ],
      "children": [
        13
      ]
    },
    {
      "id": 13,
      "text": "Conclusion: Empirical evidence supports Hypothesis 2 that bagging works at least in part by shifting implicit prior/model space toward more complex models, counteracting an overly strong simplicity bias",
      "role": "Conclusion",
      "parents": [
        2,
        12
      ],
      "children": [
        14
      ]
    },
    {
      "id": 14,
      "text": "Overall conclusion: Bagging's success is unlikely due to approximating Bayesian model averaging; it plausibly works by altering the effective prior/model space (reducing simplicity bias), as shown by meta-learning and complexity-error relationships",
      "role": "Conclusion",
      "parents": [
        6,
        13
      ],
      "children": null
    }
  ]
}