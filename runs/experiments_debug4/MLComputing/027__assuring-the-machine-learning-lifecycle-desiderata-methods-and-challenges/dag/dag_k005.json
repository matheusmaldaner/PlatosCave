{
  "nodes": [
    {
      "id": 0,
      "text": "Assuring machine learning requires generating evidence across the entire ML lifecycle to demonstrate ML components are safe and fit for use in safety-critical systems",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5,
        6
      ]
    },
    {
      "id": 1,
      "text": "The machine learning lifecycle consists of four stages: Data Management, Model Learning, Model Verification, and Model Deployment",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        3,
        4,
        5,
        6
      ]
    },
    {
      "id": 2,
      "text": "Assurance must produce compelling, auditable evidence so ML components can be trusted in safety-critical domains",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        15
      ]
    },
    {
      "id": 3,
      "text": "Data Management stage must produce training and verification data sets that are Relevant, Complete, Balanced, and Accurate; activities: collection, preprocessing, augmentation, analysis",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        7,
        8
      ]
    },
    {
      "id": 4,
      "text": "Model Learning stage must produce Performant, Robust, Reusable, and Interpretable models via model selection, training, hyperparameter tuning and transfer learning",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        9,
        10
      ]
    },
    {
      "id": 5,
      "text": "Model Verification stage must generate Comprehensive, Contextually Relevant, and Comprehensible verification evidence using test-based and formal verification and requirement encoding",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        11,
        12
      ]
    },
    {
      "id": 6,
      "text": "Model Deployment stage must integrate, monitor, and update models so deployed models are Fit-for-Purpose, Tolerated by system architectures, and Adaptable over time",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        13,
        14
      ]
    },
    {
      "id": 7,
      "text": "Data Management methods include trusted data sources and transit integrity, experimental design and simulation V&V, exploratory data analysis, augmentation (including adversarial examples and GANs), bias mitigation, oversampling/undersampling and configuration management",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 8,
      "text": "Open challenges for Data Management: detecting backdoors, validating synthetic data, detecting data leakage, measuring completeness for operational/failure/adversarial domains, finding small disjuncts and correcting feature imbalance, ensuring labeler consistency and simulation accuracy",
      "role": "Limitation",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 9,
      "text": "Model Learning methods include performance metrics and statistical tests, ensemble methods, hyperparameter optimization, regularization and augmentation techniques, transfer learning and model zoos, and post-hoc interpretability methods",
      "role": "Method",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 10,
      "text": "Open challenges for Model Learning: selecting context-representative measures, run-time multi-objective evaluation, context-aware hyperparameter tuning, understanding hyperparameter effects, decoupling perturbation effects, inferring contextual robustness, identifying similar operational contexts, and ensuring transferred models are fault-free; global interpretability and extracting global properties from local explanations",
      "role": "Limitation",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 11,
      "text": "Model Verification methods include requirement encoding, test-based approaches (normal and robustness tests, synthetic test generation, guided fuzzing, coverage metrics), and emerging formal methods for neural networks (SMT, abstract interpretation) and for other models (e.g., random forests), plus bias checks and probabilistic verification",
      "role": "Method",
      "parents": [
        5
      ],
      "children": null
    },
    {
      "id": 12,
      "text": "Open challenges for Model Verification: detecting and preventing typical ML errors, defining test coverage measures with theoretical and empirical justifications, formal verification beyond neural networks, mapping requirements to model features and RL states, general frameworks for context-aware synthetic tests, and using counterexamples to guide model repair and retraining",
      "role": "Limitation",
      "parents": [
        5
      ],
      "children": null
    },
    {
      "id": 13,
      "text": "Model Deployment methods include on-target numerical precision management, WCET analysis, distribution-shift monitoring, built-in tests and health monitors, environmental and subsystem monitoring, confidence measures, aggregator and monitor architectures to tolerate failures, recording evidence for post-incident analysis, and controlled update processes",
      "role": "Method",
      "parents": [
        6
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "Open challenges for Model Deployment: timely detection of distribution shift for high-dimensional data, deciding what to record for incident investigation, defining reliable confidence measures, designing suitably flexible safety monitors and aggregators, understanding achievable independence among models trained on same data, and managing fleet-wide diversity during updates",
      "role": "Limitation",
      "parents": [
        6
      ],
      "children": null
    },
    {
      "id": 15,
      "text": "Conclusion: existing methods cover many assurance needs across the lifecycle but substantial research is still required across all stages to close gaps and enable safe use of ML in safety-critical systems",
      "role": "Conclusion",
      "parents": [
        2,
        3,
        4,
        5,
        6
      ],
      "children": null
    }
  ]
}