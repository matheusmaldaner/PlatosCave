{
  "nodes": [
    {
      "id": 0,
      "text": "Assuring machine learning across its entire lifecycle is necessary to generate the evidence required to safely deploy ML components in safety-critical systems",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5,
        6
      ]
    },
    {
      "id": 1,
      "text": "The machine learning lifecycle is a four-stage iterative process (Data Management, Model Learning, Model Verification, Model Deployment) that produces, verifies and integrates ML models into systems",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        2,
        3,
        4,
        5
      ]
    },
    {
      "id": 2,
      "text": "Data Management comprises collection, preprocessing, augmentation and analysis to produce training and independent verification data sets",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        6
      ]
    },
    {
      "id": 3,
      "text": "Model Learning involves model selection, training, hyperparameter tuning and transfer learning to produce models that are performant, robust, reusable and interpretable",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        6
      ]
    },
    {
      "id": 4,
      "text": "Model Verification encodes requirements into tests and formal properties, and uses test-based and formal verification to produce a verification result and a verified model",
      "role": "Method",
      "parents": [
        0,
        1
      ],
      "children": [
        6
      ]
    },
    {
      "id": 5,
      "text": "Model Deployment integrates verified models into systems and addresses integration, monitoring and updating so deployed models are fit-for-purpose, tolerated by system architectures, and adaptable",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        6
      ]
    },
    {
      "id": 6,
      "text": "A repertoire of assurance methods exists mapped to lifecycle stages (data source validation, experimental design, augmentation, EDA; model performance metrics, ensembles, regularization, transfer learning; test-based methods, adversarial and formal verification; monitors, redundancy, update management) but applicability and coverage vary by stage and model type",
      "role": "Evidence",
      "parents": [
        2,
        3,
        4,
        5
      ],
      "children": [
        7,
        8
      ]
    },
    {
      "id": 7,
      "text": "Significant open challenges remain across the lifecycle including: detecting data backdoors and leakage, measuring completeness for operational/failure/adversarial domains, hyperparameter impact and tuning, interpretability at global scale, formal verification beyond neural nets, context-aware test generation, distribution shift detection, runtime confidence measures, and fleet update control",
      "role": "Claim",
      "parents": [
        6
      ],
      "children": [
        9
      ]
    },
    {
      "id": 8,
      "text": "Existing surveys are narrower in scope (focusing on specific ML types or verification techniques); this work is a comprehensive survey tying assurance desiderata, methods and open challenges to lifecycle stages",
      "role": "Context",
      "parents": [
        1
      ],
      "children": null
    },
    {
      "id": 9,
      "text": "Conclusion: achieving the safe use of ML in safety-critical systems requires coordinated research addressing data fitness and security, model robustness and interpretability, verifiable testing and formal methods, and deployment monitoring and update assurance",
      "role": "Conclusion",
      "parents": [
        7,
        6
      ],
      "children": null
    }
  ]
}