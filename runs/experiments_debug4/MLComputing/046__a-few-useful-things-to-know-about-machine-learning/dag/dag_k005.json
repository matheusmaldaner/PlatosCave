{
  "nodes": [
    {
      "id": 0,
      "text": "Machine learning systems can automatically learn programs from data and the central goal is to produce classifiers that generalize well to unseen examples",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12,
        13,
        14
      ]
    },
    {
      "id": 1,
      "text": "Learning algorithms decompose into three interdependent components: representation, evaluation, and optimization",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        2,
        6
      ]
    },
    {
      "id": 2,
      "text": "Representation choice determines the hypothesis space and which classifiers can possibly be learned",
      "role": "Claim",
      "parents": [
        1
      ],
      "children": [
        11,
        12
      ]
    },
    {
      "id": 3,
      "text": "Generalization to unseen data is the fundamental objective and training performance is a poor proxy unless properly controlled",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        4,
        5,
        6
      ]
    },
    {
      "id": 4,
      "text": "Contaminating test data (for example by tuning on it) and evaluating on training data give misleading success; holdout sets or cross-validation should be used",
      "role": "Method",
      "parents": [
        3
      ],
      "children": [
        7
      ]
    },
    {
      "id": 5,
      "text": "Cross-validation helps estimate generalization but can itself overfit if used for too many parameter choices",
      "role": "Limitation",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 6,
      "text": "Because the objective we care about (test error) is not directly available, evaluation and optimization choices are proxies and influence the learned classifier",
      "role": "Claim",
      "parents": [
        1,
        3
      ],
      "children": [
        4,
        9
      ]
    },
    {
      "id": 7,
      "text": "Regularization, statistical significance tests and cross-validation are common techniques to combat overfitting",
      "role": "Method",
      "parents": [
        4
      ],
      "children": [
        5
      ]
    },
    {
      "id": 8,
      "text": "Data alone is insufficient: learners require prior assumptions or knowledge to generalize beyond finite data (no free lunch)",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        2,
        11
      ]
    },
    {
      "id": 9,
      "text": "Overfitting arises when learned classifiers encode random quirks of training data; it can be analyzed via bias and variance decomposition",
      "role": "Claim",
      "parents": [
        3,
        6
      ],
      "children": [
        7
      ]
    },
    {
      "id": 10,
      "text": "The curse of dimensionality makes generalization exponentially harder as feature dimensionality grows, undermining similarity-based methods and intuition",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        11,
        12
      ]
    },
    {
      "id": 11,
      "text": "Effective learning exploits domain structure or lower effective dimensionality (blessing of nonuniformity) and benefits from appropriate representation and feature design",
      "role": "Claim",
      "parents": [
        2,
        8,
        10
      ],
      "children": [
        12,
        13
      ]
    },
    {
      "id": 12,
      "text": "Feature engineering is the most important practical factor for success; constructing informative features and preprocessing data often dominates algorithm choice",
      "role": "Claim",
      "parents": [
        11
      ],
      "children": [
        14
      ]
    },
    {
      "id": 13,
      "text": "More data often yields bigger gains than designing a better algorithm: a simple algorithm with lots of data can outperform a clever one with little data",
      "role": "Claim",
      "parents": [
        0,
        11
      ],
      "children": [
        14
      ]
    },
    {
      "id": 14,
      "text": "Model ensembles (bagging, boosting, stacking) reduce variance and typically improve predictive performance relative to single learners",
      "role": "Claim",
      "parents": [
        0,
        9,
        13
      ],
      "children": [
        15
      ]
    },
    {
      "id": 15,
      "text": "Theoretical generalization guarantees exist but are often loose, asymptotic, or depend on hypothesis space choices and do not substitute for empirical validation",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        16
      ]
    },
    {
      "id": 16,
      "text": "Representability of a function by a model class does not imply it is learnable in practice given finite data, computation, and local optima; learning deeper representations is an active research frontier",
      "role": "Claim",
      "parents": [
        2,
        15
      ],
      "children": [
        17
      ]
    },
    {
      "id": 17,
      "text": "Correlation learned from observational data does not imply causation; experiments or careful causal analysis are required to predict effects of actions",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        18
      ]
    },
    {
      "id": 18,
      "text": "Conclusions and best practices: try simple learners first, invest in feature engineering and data, use holdout validation and ensembles, be skeptical of simple rules like 'simpler models always generalize better', and seek experiments when causal claims matter",
      "role": "Conclusion",
      "parents": [
        12,
        13,
        14,
        15,
        16,
        17
      ],
      "children": null
    }
  ]
}