{
  "nodes": [
    {
      "id": 0,
      "text": "Summarize and communicate practical \"folk knowledge\" about machine learning so practitioners can build more successful ML applications",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ]
    },
    {
      "id": 1,
      "text": "Effective learning systems decompose into three components: representation, evaluation, and optimization, and choices among these determine what can be learned and how efficiently",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 2,
      "text": "The fundamental goal of machine learning is generalization to unseen data, not training accuracy, so train/test separation and cross validation are essential",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 3,
      "text": "Data alone is insufficient to generalize; learners must incorporate prior knowledge or assumptions (inductive bias) to perform better than random",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 4,
      "text": "Overfitting arises when learned classifiers capture random quirks of training data; it manifests via bias and variance and requires methods like regularization, significance testing, and careful validation",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 5,
      "text": "High dimensionality makes learning and similarity reasoning difficult (curse of dimensionality), though data often lie near lower dimensional manifolds which mitigates the problem",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 6,
      "text": "Feature engineering is the most important practical factor for success: designing and preprocessing informative features typically dominates algorithm choice and training time",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 7,
      "text": "In practice more data often outperforms more sophisticated algorithms: a simple algorithm with lots of data can beat a clever one with modest data, though scalability and computational cost matter",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 8,
      "text": "Combining many models into ensembles (bagging, boosting, stacking) reliably improves predictive performance by reducing variance and exploiting complementary strengths",
      "role": "Result",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 9,
      "text": "Theoretical guarantees (sample complexity bounds, asymptotic consistency) exist and provide insight but are often loose or inapplicable in practical finite-data regimes",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 10,
      "text": "Representability does not imply learnability: a function class may be representable by a model but still unlearnable in practice due to limited data, computational constraints, or local optima",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 11,
      "text": "Correlation does not imply causation: learners of observational data typically learn correlations, so causal conclusions require experimental data or specialized methods",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 12,
      "text": "Practical machine learning success depends on choosing appropriate representations, preventing overfitting, engineering good features, leveraging data and ensembles, and understanding theoretical limits and causal assumptions",
      "role": "Conclusion",
      "parents": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11
      ],
      "children": null
    }
  ]
}