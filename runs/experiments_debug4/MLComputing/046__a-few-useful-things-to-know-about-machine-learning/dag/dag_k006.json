{
  "nodes": [
    {
      "id": 0,
      "text": "Applying practical \"folk knowledge\" and the twelve key lessons summarized by the author improves the success of machine learning applications",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11,
        12
      ]
    },
    {
      "id": 1,
      "text": "Learning systems decompose into three core components: representation, evaluation, and optimization; choices among these determine what can be learned and how efficiently",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        2,
        3,
        10
      ]
    },
    {
      "id": 2,
      "text": "The principal goal of machine learning is generalization to unseen data, so separating training and test data and using proper evaluation is essential",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        5,
        12
      ]
    },
    {
      "id": 3,
      "text": "Data alone is insufficient for generalization; learners require prior knowledge or assumptions (bias) to extrapolate beyond observed examples",
      "role": "Claim",
      "parents": [
        0,
        1
      ],
      "children": [
        4,
        6
      ]
    },
    {
      "id": 4,
      "text": "No free lunch theorem and related reasoning imply no learner can be uniformly superior without domain assumptions",
      "role": "Assumption",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 5,
      "text": "Overfitting arises when learned hypotheses fit training quirks rather than true regularities; it manifests as high variance or low bias depending on learner",
      "role": "Claim",
      "parents": [
        2,
        3
      ],
      "children": [
        7,
        12
      ]
    },
    {
      "id": 6,
      "text": "Feature representations express domain knowledge; choosing or constructing features that encode relevant knowledge is critical to learning success",
      "role": "Claim",
      "parents": [
        1,
        3
      ],
      "children": [
        8,
        9
      ]
    },
    {
      "id": 7,
      "text": "Practical methods to mitigate overfitting include strict train/test separation, cross-validation, regularization, statistical significance tests, and controlling false discovery rate",
      "role": "Method",
      "parents": [
        5
      ],
      "children": null
    },
    {
      "id": 8,
      "text": "Feature engineering typically dominates effort in applied projects: gathering, cleaning, transforming data and constructing features is the main driver of success",
      "role": "Result",
      "parents": [
        6
      ],
      "children": [
        9,
        12
      ]
    },
    {
      "id": 9,
      "text": "Automatic feature generation and selection can help but have limits because features may be relevant only in complex combinations and can cause overfitting or computational cost",
      "role": "Limitation",
      "parents": [
        6
      ],
      "children": null
    },
    {
      "id": 10,
      "text": "High dimensionality (curse of dimensionality) degrades similarity-based reasoning and makes generalization exponentially harder unless data lie near a lower-dimensional manifold",
      "role": "Claim",
      "parents": [
        1
      ],
      "children": [
        11
      ]
    },
    {
      "id": 11,
      "text": "Dimensionality can be mitigated by exploiting non-uniformity of real data (lower effective dimensional manifolds) or by explicit dimensionality reduction",
      "role": "Method",
      "parents": [
        10
      ],
      "children": null
    },
    {
      "id": 12,
      "text": "More data often provides a faster, more pragmatic route to improved performance than designing slightly better algorithms, though scalability and computation time can limit this",
      "role": "Claim",
      "parents": [
        0,
        8
      ],
      "children": [
        13
      ]
    },
    {
      "id": 13,
      "text": "Model ensembles (bagging, boosting, stacking) empirically reduce variance and improve accuracy; large ensembles won the Netflix prize and enhanced performance beyond single learners",
      "role": "Evidence",
      "parents": [
        12
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "Theoretical guarantees (sample complexity bounds, asymptotic correctness) exist and provide understanding, but are often loose or not directly useful for practical finite-data decisions",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 15,
      "text": "Correlation discovered by learners does not imply causation; observational predictive models can guide experiments but causal conclusions require experimental data or restricted methods",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": null
    }
  ]
}