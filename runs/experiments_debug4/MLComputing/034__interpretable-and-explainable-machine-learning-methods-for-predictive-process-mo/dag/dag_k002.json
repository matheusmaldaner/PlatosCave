{
  "nodes": [
    {
      "id": 0,
      "text": "A systematic literature review (SLR) can synthesize the state of interpretable and explainable machine learning methods for predictive process monitoring (PPM), identify prevailing practices and gaps, and produce an evidence-based research agenda for advancing trustworthy, transparent predictive process analytics",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        10,
        12,
        14
      ]
    },
    {
      "id": 1,
      "text": "Method: Performed a PRISMA-based systematic literature review with searches across ACM, AIS, IEEE Xplore, Science Direct, SpringerLink and forward/backward search yielding 1,415 records and including 107 studies after screening and eligibility checks",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        15
      ]
    },
    {
      "id": 2,
      "text": "Formal foundations and scope: Provided formal definitions for PPM data constructs (event, trace, event log), feature extraction, labeling, supervised learning paradigms and taxonomy distinguishing intrinsically interpretable models and black-box models plus local/global post-hoc explanations",
      "role": "Context",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 3,
      "text": "Corpus-level findings: Analyzed 107 publications (53 journals, 51 conferences, 3 arXiv); publication spike since 2020; template analysis mapped studies to eight research questions (RQ1â€“RQ8)",
      "role": "Result",
      "parents": [
        0
      ],
      "children": [
        4,
        5,
        6
      ]
    },
    {
      "id": 4,
      "text": "Datasets and application domains: BPIC datasets dominate (used in 61/107 studies, BPIC2012 most used), frequent domains are finance (55 studies), healthcare (31), customer support (25), manufacturing (16); 42 studies domain-agnostic",
      "role": "Evidence",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 5,
      "text": "Prediction tasks distribution: Process outcome prediction is most studied (65 articles), next-event prediction (30 articles), time-related PPI regression tasks (23 articles) and other PPI predictions appear less frequently",
      "role": "Result",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 6,
      "text": "Modeling and explanation landscape: Both intrinsically interpretable (white-box) and opaque (black-box) models are used; many black-boxs require post-hoc explanations and researchers apply a range of explanation techniques",
      "role": "Claim",
      "parents": [
        3
      ],
      "children": [
        7,
        8,
        9
      ]
    },
    {
      "id": 7,
      "text": "Interpretable models used: Decision trees are the most prevalent white-box models (22 of 64 white-box papers), with logistic/linear regression, Bayesian networks, rule-based systems, k-NN and GAMs also used where interpretability is important",
      "role": "Evidence",
      "parents": [
        6
      ],
      "children": null
    },
    {
      "id": 8,
      "text": "Black-box models used: Deep learning (DNN/RNN/LSTM) used heavily (38 of 59 black-box papers), gradient boosting (XGBoost etc.) used in 26, random forests in 16, plus some specialized opaque approaches and ensembles",
      "role": "Evidence",
      "parents": [
        6
      ],
      "children": null
    },
    {
      "id": 9,
      "text": "Post-hoc explanation methods observed: Common techniques include local methods (LIME, SHAP, ICE, LRP, counterfactuals) and global methods (PDP, aggregated SHAP, feature importance, global surrogates); explanations produced in numeric, rule-based, textual and visual formats",
      "role": "Evidence",
      "parents": [
        6
      ],
      "children": null
    },
    {
      "id": 10,
      "text": "Evaluation gap: Most reviewed studies prioritize predictive performance over systematic explanation evaluation; only a minority performed formal explainability evaluation (about 18 papers used quantitative or qualitative evaluation) and human-grounded studies are scarce",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        11
      ]
    },
    {
      "id": 11,
      "text": "Evaluation methods and metrics cataloged: Papers report metrics and paradigms including fidelity, stability, sparsity, functional/application/human-grounded evaluations, internal vs external fidelity, explanation complexity, plausibility and counterfactual quality measures",
      "role": "Method",
      "parents": [
        10
      ],
      "children": null
    },
    {
      "id": 12,
      "text": "Challenges and open issues identified: Fragmented literature, dataset and domain biases (BPIC dominance), encoding choices affecting reproducibility, lack of standardized evaluation, limited real-world and cross-domain validation, and insufficient treatment of streaming and object-centric cases",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        13
      ]
    },
    {
      "id": 13,
      "text": "Research agenda and future directions: Priorities include systematic study of encoding impacts; combining XAI with trustworthy AI aspects (uncertainty quantification, privacy, fairness); LLM-driven conversational and multi-modal explanations; low-latency explanations for streaming data; and object-centric process mining (OCPM) explainers",
      "role": "Conclusion",
      "parents": [
        12
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "Practical implications and recommendations: For practitioners match model and explanation type to domain and task, evaluate explanation fidelity and stability, consider regulatory, deployment and user-training constraints, and avoid adopting explanations without human-centered validation",
      "role": "Conclusion",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 15,
      "text": "SLR limitations: Search confined to selected databases and query formulations, possible omission of papers not indexed or using alternative terminology, and reliance on reported evaluation practices in source papers",
      "role": "Limitation",
      "parents": [
        1
      ],
      "children": null
    }
  ]
}