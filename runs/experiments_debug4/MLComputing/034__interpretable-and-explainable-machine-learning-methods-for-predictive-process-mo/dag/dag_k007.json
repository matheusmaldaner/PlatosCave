{
  "nodes": [
    {
      "id": 0,
      "text": "A systematic synthesis of interpretable and explainable machine learning methods for predictive process monitoring (PPM) can map the field, identify trends and gaps, and produce an evidence-based research agenda to make PPM systems more transparent, trustworthy and effective",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5,
        6,
        7
      ]
    },
    {
      "id": 1,
      "text": "Method: Conducted a PRISMA-based systematic literature review covering the last decade up to 2025, applying structured eligibility criteria, forward/backward search and template analysis to extract evidence from selected studies",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        2
      ]
    },
    {
      "id": 2,
      "text": "Result: 1,415 records identified, screened to 136 full texts and finally 107 studies included for synthesis; metadata shows majority published since 2020 across journals and conferences",
      "role": "Result",
      "parents": [
        1
      ],
      "children": [
        3
      ]
    },
    {
      "id": 3,
      "text": "Context / Definitions: Formalized PPM data constructs (event, trace, event log), feature extraction and labeling, supervised learning tasks (next event, outcome, time-related and other PPIs), and distinction between intrinsically interpretable models and black-box models requiring post-hoc explanations",
      "role": "Context",
      "parents": [
        1
      ],
      "children": [
        4,
        5
      ]
    },
    {
      "id": 4,
      "text": "Result: Application domains and datasets — finance (most frequent), healthcare, customer support and manufacturing dominate; BPIC suite widely used (57% of papers used at least one BPIC), with BPIC2012 most common; many studies are domain-agnostic but dataset availability skews research focus",
      "role": "Result",
      "parents": [
        2,
        3
      ],
      "children": [
        6
      ]
    },
    {
      "id": 5,
      "text": "Result: Prediction tasks distribution — process outcome prediction is most common (65 papers), next-event prediction (30 papers), time-related regression tasks (32 papers) and other PPIs (15 papers); task type influences model and explanation selection",
      "role": "Result",
      "parents": [
        2,
        3
      ],
      "children": [
        6
      ]
    },
    {
      "id": 6,
      "text": "Result: Model and explanation landscape — white-box models (decision trees, logistic/linear regression, Bayesian networks, rule-based systems, GAMs, k-NN) used in many studies (64), black-box models (deep learning, gradient boosting, random forests) used in many others (59); popular post-hoc methods include SHAP, LIME, ICE, PDP, counterfactuals and model-specific techniques like LRP and TreeSHAP",
      "role": "Result",
      "parents": [
        4,
        5,
        3
      ],
      "children": [
        8,
        9
      ]
    },
    {
      "id": 7,
      "text": "Method: Data extraction and synthesis used a template aligned to research questions (RQ1–RQ8) covering application domain, datasets, tasks, intrinsic models, post-hoc methods, and evaluation paradigms, with coding iteration until saturation",
      "role": "Method",
      "parents": [
        1
      ],
      "children": [
        6
      ]
    },
    {
      "id": 8,
      "text": "Evidence: Quantitative counts and patterns — decision trees were the most prevalent interpretable model (22 of 64 white-box studies); deep learning (especially LSTM) appears in 38 black-box studies; gradient boosting and XGBoost used in 26 black-box studies; SHAP and LIME are the dominant post-hoc explainers",
      "role": "Evidence",
      "parents": [
        6
      ],
      "children": [
        10
      ]
    },
    {
      "id": 9,
      "text": "Claim: Trade-off observed — opaque models often yield higher predictive accuracy but require post-hoc explanations, while white-box models are more transparent but often underperform on complex PPM tasks",
      "role": "Claim",
      "parents": [
        6
      ],
      "children": [
        10
      ]
    },
    {
      "id": 10,
      "text": "Result / Evidence: Evaluation practices are weak — majority of reviewed papers did not perform formal explanation evaluation; only about 18 papers used quantitative or qualitative evaluation and only two combined both; human-grounded evaluations are scarce",
      "role": "Result",
      "parents": [
        8,
        9
      ],
      "children": [
        11,
        12
      ]
    },
    {
      "id": 11,
      "text": "Claim: Critical gaps identified — inconsistent or missing evaluation of explanation quality (fidelity, stability, plausibility), dataset biases and transferability issues, methodological choices (trace encoding) underreported and influential, and lack of studies on streaming/real-time, object-centric logs and integrated trustworthy AI aspects",
      "role": "Claim",
      "parents": [
        10,
        4,
        6
      ],
      "children": [
        13
      ]
    },
    {
      "id": 12,
      "text": "Claim: Taxonomy and synthesis contribution — the review classifies intrinsically interpretable models and post-hoc explanation approaches (local vs global, model-agnostic vs model-specific), maps datasets, tasks and evaluation paradigms, and provides consolidated evidence for practitioners and researchers",
      "role": "Claim",
      "parents": [
        1,
        6
      ],
      "children": [
        13
      ]
    },
    {
      "id": 13,
      "text": "Conclusion / Future directions: Research agenda emphasizes (1) rigorous, multi-dimensional evaluation including human-grounded studies; (2) study of encoding effects and benchmarking; (3) development of XAI for streaming PPM and object-centric process mining; (4) integration of XAI with uncertainty quantification, fairness and privacy-preserving methods; and (5) exploring LLMs and conversational XAI for interactive explanations",
      "role": "Conclusion",
      "parents": [
        11,
        12
      ],
      "children": [
        14
      ]
    },
    {
      "id": 14,
      "text": "Limitation: SLR constraints include database selection and query formulation which may omit some relevant works, and the review reflects evidence up to 2025",
      "role": "Limitation",
      "parents": [
        1
      ],
      "children": null
    }
  ]
}