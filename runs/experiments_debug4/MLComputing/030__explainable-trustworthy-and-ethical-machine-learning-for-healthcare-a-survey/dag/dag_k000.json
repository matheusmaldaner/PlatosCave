{
  "nodes": [
    {
      "id": 0,
      "text": "Explainable, trustworthy, and ethical machine learning methods are necessary for safe clinical deployment of ML/DL in healthcare",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5
      ]
    },
    {
      "id": 1,
      "text": "Deep learning models achieve state-of-the-art performance in many healthcare tasks but have a black-box nature that hinders clinician and patient trust",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        6,
        7
      ]
    },
    {
      "id": 2,
      "text": "Explainable ML (XML) methods can increase transparency, enable validation, and help resolve ethical problems arising from ML use in healthcare",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        8,
        9
      ]
    },
    {
      "id": 3,
      "text": "There are important trade-offs and interactions among accuracy, explainability, robustness, privacy, and safety that must be managed for trustworthy healthcare AI",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        10,
        11
      ]
    },
    {
      "id": 4,
      "text": "A pipeline for explainable ML in healthcare should include data explanation, model-structure explanation, result explanation, and evaluation of explanation effectiveness before deployment",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 5,
      "text": "Ethical principles (beneficence, non-maleficence, autonomy, justice) and recent AI guidelines require explainability, transparency, privacy protection, fairness, and accountability in healthcare AI",
      "role": "Context",
      "parents": [
        0
      ],
      "children": [
        2,
        3
      ]
    },
    {
      "id": 6,
      "text": "Lack of formal definitions, standardized representations, and standardized requirements for XML in healthcare impede consistent development and evaluation of explanations",
      "role": "Claim",
      "parents": [
        1
      ],
      "children": [
        7
      ]
    },
    {
      "id": 7,
      "text": "Validation of explanations is weak: there are no widely accepted metrics or ground truths to compare and quantify explanation quality across methods",
      "role": "Claim",
      "parents": [
        6
      ],
      "children": [
        11
      ]
    },
    {
      "id": 8,
      "text": "Multiple model-agnostic and model-specific explanation methods exist (e.g., LIME, SHAP, CAM, Grad-CAM, LRP, Integrated Gradients, DeepLIFT, PDP) and have been applied to healthcare tasks",
      "role": "Evidence",
      "parents": [
        2
      ],
      "children": [
        9
      ]
    },
    {
      "id": 9,
      "text": "Application examples in literature show explanations for medical imaging, EHR, genomics, and prediction tasks, but explanations can be noisy, model-dependent, and sometimes misaligned with human judgments",
      "role": "Result",
      "parents": [
        8
      ],
      "children": [
        7,
        11
      ]
    },
    {
      "id": 10,
      "text": "Adversarial attacks and privacy vulnerabilities have been demonstrated on medical ML systems (e.g., CT-GAN manipulations, attacks on ECG and imaging classifiers), showing security risks to patient safety",
      "role": "Evidence",
      "parents": [
        3
      ],
      "children": [
        11
      ]
    },
    {
      "id": 11,
      "text": "Robustness to adversarial attacks, distributional shifts, and data imperfections is required and often conflicts with maximizing standard accuracy; robust models may be more explainable but less accurate in standard metrics",
      "role": "Claim",
      "parents": [
        3,
        10,
        9
      ],
      "children": [
        12
      ]
    },
    {
      "id": 12,
      "text": "Future research directions include explaining and auditing medical data, developing standardized and domain-adapted explanation representations, creating generalized and robust XML methods, and building interdisciplinary development teams",
      "role": "Conclusion",
      "parents": [
        4,
        11
      ],
      "children": [
        13
      ]
    },
    {
      "id": 13,
      "text": "Clinical deployment requires rigorous evaluation, human-grounded and application-based testing of explanations, privacy-preserving techniques, and regulatory/ethical governance to ensure informed consent and accountability",
      "role": "Conclusion",
      "parents": [
        12,
        5
      ],
      "children": null
    }
  ]
}