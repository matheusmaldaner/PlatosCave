{
  "nodes": [
    {
      "id": 0,
      "text": "Explainable, trustworthy, and ethical machine learning (XML) is required to enable safe clinical deployment of ML/DL in healthcare by increasing transparency, clinician and patient trust, and addressing liability and ethical concerns",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5
      ]
    },
    {
      "id": 1,
      "text": "Deep learning models achieve high performance on many healthcare tasks but are black-boxes lacking theoretical foundations and interpretability, which impedes clinical trust and adoption",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        6,
        7
      ]
    },
    {
      "id": 2,
      "text": "Explainable ML methods (intrinsic, post-hoc, model-specific, model-agnostic, surrogate, visualization) can provide local and global explanations and are necessary to interpret model logic and input-output relevance",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        8,
        9
      ]
    },
    {
      "id": 3,
      "text": "Trustworthy ML for healthcare requires addressing security, robustness, privacy, fairness, and accountability alongside explanation to meet OECD and EU HLEG principles",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        10,
        11
      ]
    },
    {
      "id": 4,
      "text": "Ethical issues—data bias, privacy breaches, informed consent challenges, and impacts on care relationships—must be handled through explainability, governance, and interdisciplinary development",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12,
        13
      ]
    },
    {
      "id": 5,
      "text": "There are practical trade-offs: improving robustness or interpretability often reduces standard accuracy, and vice versa, so design choices must balance accuracy, explainability, and safety",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 6,
      "text": "DL architectures (multiple nonlinear layers) produce more accurate results than conventional ML for tasks like imaging, EHR management, segmentation, and prediction but produce opaque decisions that can be life-threatening if unexplainable",
      "role": "Evidence",
      "parents": [
        1
      ],
      "children": null
    },
    {
      "id": 7,
      "text": "Black-box behavior and lack of causality/theoretical understanding limit generalization and create vulnerabilities (adversarial attacks, distribution shifts, data leakage)",
      "role": "Claim",
      "parents": [
        1
      ],
      "children": [
        14
      ]
    },
    {
      "id": 8,
      "text": "A proposed XML pipeline: explain data (detect bias, leakage), explain model structure (intrinsic or surrogate models), explain results (feature relevance, local/global), and measure explanation effectiveness via application-, human-, and function-based evaluation",
      "role": "Method",
      "parents": [
        2
      ],
      "children": [
        9
      ]
    },
    {
      "id": 9,
      "text": "Common explainability techniques applied in healthcare include white-box models (decision trees, GAM), model-agnostic methods (LIME, SHAP, PDP), saliency and attribution (CAM, Grad-CAM, LRP, IG, DeepLIFT, Guided BP), and interpretable DL (HSCNN, P2V, EMANet)",
      "role": "Evidence",
      "parents": [
        2,
        8
      ],
      "children": null
    },
    {
      "id": 10,
      "text": "Security and robustness must cover adversarial robustness (attacks that add/remove medical evidence), privacy-preserving training/inference (federated learning, differential privacy, homomorphic encryption), and robustness to distribution shifts and data imperfections",
      "role": "Claim",
      "parents": [
        3
      ],
      "children": [
        14
      ]
    },
    {
      "id": 11,
      "text": "Trustworthy AI principles (human-centered values, transparency, technical robustness, privacy, fairness, accountability) should guide design, testing and deployment of ML in healthcare",
      "role": "Conclusion",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 12,
      "text": "Data-related ethical challenges include imbalanced and biased datasets (gender, race, socioeconomic, geographic biases) and risks from unprotected data sharing or misuse that undermine fairness and privacy",
      "role": "Evidence",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 13,
      "text": "The black-box nature challenges obtaining informed consent and accountability; explainability and transparent governance are ethically required to inform patients and assign responsibility",
      "role": "Claim",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "Open research needs: methods to explain medical data and representations, standardized explanation formats and validation metrics, generalized and robust explainers, adversarial defenses, and interdisciplinary development teams",
      "role": "Conclusion",
      "parents": [
        7,
        10
      ],
      "children": null
    }
  ]
}