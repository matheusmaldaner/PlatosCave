{
  "nodes": [
    {
      "id": 0,
      "text": "Explainable, trustworthy, and ethical machine learning is necessary to safely deploy ML/DL systems in healthcare",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5
      ]
    },
    {
      "id": 1,
      "text": "Lack of explainability of deep learning models hinders clinician and patient trust because black-box decisions can be life-threatening in healthcare",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        6,
        7
      ]
    },
    {
      "id": 2,
      "text": "Security, safety, robustness, and ethical challenges (adversarial attacks, privacy breaches, data bias, lack of causality) undermine trustworthiness of ML in clinical settings",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        8,
        9
      ]
    },
    {
      "id": 3,
      "text": "A pipeline for explainable ML in healthcare should include data explanation, model-structure explanation, result explanation, and evaluation before clinical deployment",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        10,
        11
      ]
    },
    {
      "id": 4,
      "text": "Explainability taxonomies and methods (intrinsic vs post-hoc, model-specific vs model-agnostic, local vs global, white/grey/black-box methods) provide a framework to select explainers for healthcare tasks",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        12
      ]
    },
    {
      "id": 5,
      "text": "Ethical principles (beneficence, non-maleficence, autonomy, justice) and emerging explicability norms must be integrated into ML development and deployment for healthcare",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        13
      ]
    },
    {
      "id": 6,
      "text": "Examples show explanations help detect dataset problems and spurious correlations (e.g., pneumonia model learned treatment proxies like asthma leading to misleading mortality risk)",
      "role": "Evidence",
      "parents": [
        1
      ],
      "children": null
    },
    {
      "id": 7,
      "text": "Clinicians and patients require domain-adaptable, transparent, and adoptable explanation outputs (visual, textual, rule-based) to understand and trust model decisions",
      "role": "Claim",
      "parents": [
        1
      ],
      "children": null
    },
    {
      "id": 8,
      "text": "Adversarial attacks have been demonstrated on medical imaging and signals (CT manipulation, ECG, skin/retina image attacks), showing real clinical safety threats",
      "role": "Evidence",
      "parents": [
        2
      ],
      "children": null
    },
    {
      "id": 9,
      "text": "Privacy attacks, distributional shift, imbalanced and biased datasets lead to unfair, non-generalizable, or privacy-violating outcomes in healthcare ML",
      "role": "Claim",
      "parents": [
        2
      ],
      "children": null
    },
    {
      "id": 10,
      "text": "Data explanation step can reveal biases, leakage, and dependencies (e.g., socioeconomic, gender, geographic biases) before model training",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 11,
      "text": "Evaluating explanations requires application-based, human-based, and function-based assessments since no single objective metric exists",
      "role": "Method",
      "parents": [
        3
      ],
      "children": [
        14
      ]
    },
    {
      "id": 12,
      "text": "Model-agnostic methods (LIME, SHAP, PDP, CAM, LRP, DeepLIFT, Grad-CAM, GBP, IG) and intrinsic interpretable models (DTs, GAMs, rule-lists, RF) have been applied to many healthcare tasks",
      "role": "Evidence",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 13,
      "text": "Informed consent, data governance, and interdisciplinary development including clinicians and ethicists are necessary to address ethical and practical deployment issues",
      "role": "Claim",
      "parents": [
        5
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "There are trade-offs: improving adversarial robustness or explainability often reduces nominal accuracy, so design must balance accuracy, explainability, and robustness",
      "role": "Claim",
      "parents": [
        11
      ],
      "children": [
        15
      ]
    },
    {
      "id": 15,
      "text": "Open research directions include explaining medical data representations, standardized representation and evaluation of explanations, generalized explainers, adversarially robust methods, and interdisciplinary teams",
      "role": "Conclusion",
      "parents": [
        14,
        2,
        3,
        4,
        5
      ],
      "children": null
    }
  ]
}