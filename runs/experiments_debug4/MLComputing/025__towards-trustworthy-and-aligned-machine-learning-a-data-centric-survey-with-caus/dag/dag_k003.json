{
  "nodes": [
    {
      "id": 0,
      "text": "A data-centric perspective unifies trustworthy machine learning methods across robustness, adversarial robustness, interpretability, and fairness, and Pearl's causal hierarchy provides a principled framework connecting these techniques",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4,
        5
      ]
    },
    {
      "id": 1,
      "text": "Many disparate methods in trustworthy ML converge to two central empirical formulations: (A) representation invariance via an adversarial discriminator (DANN-style) and (B) worst-case data augmentation (adversarial training), with optional sample reweighting",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        6,
        7,
        8
      ]
    },
    {
      "id": 2,
      "text": "Structural causal models (SCMs) and Pearl's three-level causal hierarchy (associational L1, interventional L2, counterfactual L3) explain why data-centric interventions reduce reliance on spurious features and improve trustworthiness",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        9,
        10,
        11
      ]
    },
    {
      "id": 3,
      "text": "Techniques that implement interventions or adjustments (randomized augmentation seen as RCT, instrument variables, backdoor and frontdoor adjustments, inverse-propensity weighting) can de-confound model training and approximate do-operations from observational data",
      "role": "Claim",
      "parents": [
        0,
        2
      ],
      "children": [
        12,
        13,
        14
      ]
    },
    {
      "id": 4,
      "text": "The same data-centric and causal principles apply to large pretrained models via fine-tuning, parameter-efficient tuning, prompting, and RLHF; ERM-based master equations extend to these paradigms enabling many trustworthy techniques to transfer",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        15,
        16
      ]
    },
    {
      "id": 5,
      "text": "Stakeholder specifications (what shifts/attributes to be robust or fair to) are necessary: trustworthiness cannot be evaluated or achieved without defining the desired invariances or constraints",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": null
    },
    {
      "id": 6,
      "text": "DANN-style methods train a representation fk(x; theta) jointly with an adversary h to remove domain or spurious information via min max objectives (invariance regularization)",
      "role": "Method",
      "parents": [
        1
      ],
      "children": [
        3
      ]
    },
    {
      "id": 7,
      "text": "Worst-case data augmentation / adversarial training generates x' under constraints and optimizes model to minimize max loss over x', optionally adding embedding consistency regularizers (TRADES/ALP)",
      "role": "Method",
      "parents": [
        1
      ],
      "children": [
        3
      ]
    },
    {
      "id": 8,
      "text": "Sample-weighting / group-DRO and inverse-propensity schemes adjust training losses by alpha(x,y,theta) to emphasize bias-conflicting or underrepresented samples and mitigate dataset bias",
      "role": "Method",
      "parents": [
        1
      ],
      "children": [
        3
      ]
    },
    {
      "id": 9,
      "text": "In SCMs for supervised tasks, causal features C generate labels Y and combine with non-causal features Ctilde to produce observations X; confounding between C and Ctilde explains spurious correlations learned by ERM",
      "role": "Context",
      "parents": [
        2
      ],
      "children": [
        11
      ]
    },
    {
      "id": 10,
      "text": "Pearl's levels impose limits: L1 (associational) cannot answer interventional or counterfactual queries; methods grounded at L2 or L3 enable stronger robustness and interpretability guarantees",
      "role": "Claim",
      "parents": [
        2
      ],
      "children": null
    },
    {
      "id": 11,
      "text": "Data augmentation that randomizes confounders is equivalent to a randomized controlled trial (intervention/do) and yields observational distributions P' where P'(x|c)=P(x|do(c)), removing spurious dependence",
      "role": "Evidence",
      "parents": [
        2,
        9
      ],
      "children": [
        3
      ]
    },
    {
      "id": 12,
      "text": "Backdoor adjustment can be approximated in high-dimensional settings by representing confounder strata and marginalizing or by normalised weighted geometric mean to produce P(y|do(x)) estimates used in training",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 13,
      "text": "Instrumental variable methods and feature-level interventions provide alternatives when confounders are unobserved, enabling unbiased causal effect estimation or invariant feature learning",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 14,
      "text": "Front-door adjustment can be implemented using intermediates (model representations Z) as mediators and two-step adjustments to estimate P(y|do(x)) without observing confounders",
      "role": "Method",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 15,
      "text": "Fine-tuning, prompting, and parameter-efficient fine-tuning are ERM parameterizations: initialize or constrain hypothesis space (theta0 or frozen Theta with small trainable theta) so master trustworthiness equations (invariance, augmentation, weighting) apply",
      "role": "Claim",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 16,
      "text": "Reinforcement learning from human feedback (RLHF) aligns models to human preferences and addresses instruction-following and safety concerns complementary to statistical/causal methods, but it does not by itself remove dataset spuriousness or social-group disparities",
      "role": "Claim",
      "parents": [
        4
      ],
      "children": null
    },
    {
      "id": 17,
      "text": "Unified practical recommendation: identify dataset spurious features or confounders, then apply one or more of (a) randomized augmentation/intervention, (b) invariance regularization (DANN/feature alignment), (c) worst-case augmentation/adversarial training, and/or (d) sample weighting or causal adjustment depending on available annotations and assumptions",
      "role": "Conclusion",
      "parents": [
        1,
        3,
        4,
        5
      ],
      "children": null
    }
  ]
}