{
  "nodes": [
    {
      "id": 0,
      "text": "The error resilience of DNN systems (software on specialized accelerators) depends on data types, numeric value ranges, data reuse, layer types and positions, and can be characterized and mitigated with low-cost, DNN-aware techniques",
      "role": "Hypothesis",
      "parents": null,
      "children": [
        1,
        2,
        3,
        4
      ]
    },
    {
      "id": 1,
      "text": "Method: We modified a DNN simulator (Tiny-CNN) to inject transient single-event bit-flip faults mapped to hardware components and executed fault injection campaigns on four convolutional networks (AlexNet, CaffeNet, NiN, ConvNet) with multiple data types",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        5,
        6
      ]
    },
    {
      "id": 2,
      "text": "Claim: Datapath and buffer faults propagate differently and must be studied separately because datapath faults are read once while buffer faults can be read multiple times due to reuse",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        7
      ]
    },
    {
      "id": 3,
      "text": "Claim: DNN architectural features such as normalization layers, pooling, ReLU, and fully-connected layers influence error masking and propagation to final outputs",
      "role": "Claim",
      "parents": [
        0
      ],
      "children": [
        8
      ]
    },
    {
      "id": 4,
      "text": "Method: Case study of Eyeriss accelerator projected to 16nm to analyze buffer SDC probabilities and compute FIT rates for components (global buffer, filter SRAM, img reg, psum reg)",
      "role": "Method",
      "parents": [
        0
      ],
      "children": [
        9
      ]
    },
    {
      "id": 5,
      "text": "Result/Evidence: SDC probability varies across networks and data types; e.g., for same data type FLOAT NiN shows higher SDCs than other networks; ConvNet (shallower) shows much higher SDC propagation",
      "role": "Result",
      "parents": [
        1
      ],
      "children": [
        10
      ]
    },
    {
      "id": 6,
      "text": "Result/Evidence: Bit-position sensitivity: for floating point only high-order exponent bits cause SDCs; for fixed-point only high-order integer bits are vulnerable; vulnerability scales with dynamic value range of the data type",
      "role": "Result",
      "parents": [
        1
      ],
      "children": [
        11
      ]
    },
    {
      "id": 7,
      "text": "Evidence: Buffer faults produce higher FIT rates than datapath faults because buffers are larger and reuse can amplify a single fault into multiple SDCs (example: Filter SRAM FIT up to 3.9 in NiN vs datapath FIT 0.004)",
      "role": "Evidence",
      "parents": [
        2
      ],
      "children": [
        9
      ]
    },
    {
      "id": 8,
      "text": "Evidence: Normalization layers (e.g., LRN) and pooling/ReLU mask many errors; experiments show Euclidean distance between faulty and golden activations drops after LRN and majority (~84%) of faults are masked by POOL or ReLU",
      "role": "Evidence",
      "parents": [
        3
      ],
      "children": null
    },
    {
      "id": 9,
      "text": "Result/Evidence (Eyeriss): Some Eyeriss buffers (global buffer, filter SRAM) can increase overall accelerator FIT by orders of magnitude (example: ConvNet global buffer FIT 87.47, filter SRAM FIT 62.74), possibly exceeding ISO 26262 budgets without protection",
      "role": "Result",
      "parents": [
        4,
        7
      ],
      "children": [
        12
      ]
    },
    {
      "id": 10,
      "text": "Claim: Large numeric deviations in activations caused by faults are likely to produce SDCs, while small deviations are more often benign; activations in each layer are bounded in a small range during error-free execution",
      "role": "Claim",
      "parents": [
        5
      ],
      "children": [
        13
      ]
    },
    {
      "id": 11,
      "text": "Implication/Evidence: Choosing data types with just-enough dynamic range reduces SDC vulnerability and datapath FIT rates by orders of magnitude (example: replacing 32b_rb10 with 32b_rb26 reduced datapath FIT from 0.42 to 0.002 for a network)",
      "role": "Evidence",
      "parents": [
        6
      ],
      "children": [
        12
      ]
    },
    {
      "id": 12,
      "text": "Claim/Conclusion: DNN systems can meet safety FIT targets (e.g., ISO 26262) when combining DNN-aware software and hardware protections that exploit observed sensitivities",
      "role": "Conclusion",
      "parents": [
        9,
        11
      ],
      "children": [
        14,
        15
      ]
    },
    {
      "id": 13,
      "text": "Method/Technique: Symptom-based Error Detector (SED): learn per-layer activation value bounds from golden runs (with a 10% cushion) and asynchronously check activations in the global buffer at layer boundaries to detect SDC-causing faults",
      "role": "Method",
      "parents": [
        10
      ],
      "children": [
        14
      ]
    },
    {
      "id": 14,
      "text": "Result/Evidence: SED evaluation: for selected DNNs and data types the detector achieved high detection metrics (paper reports symptom-based detector precision ~97.84% and recall ~92.08% for selected cases; average reductions of Eyeriss FIT from 8.55 to 0.35 for FLOAT and 2.63 to 0.79 for FLOAT16 reported)",
      "role": "Evidence",
      "parents": [
        13,
        12
      ],
      "children": null
    },
    {
      "id": 15,
      "text": "Method/Technique: Selective Latch Hardening (SLH): selectively harden the most SDC-sensitive latch bits using a mix of hardened latch designs to minimize area while maximizing FIT reduction; design-space exploration shows combining techniques yields large benefits",
      "role": "Method",
      "parents": [
        12
      ],
      "children": [
        16
      ]
    },
    {
      "id": 16,
      "text": "Result/Evidence: SLH evaluation: protecting the most sensitive bits can reduce datapath FIT by up to 100x with about 20%-25% latch area overhead in examples (AlexNet on Eyeriss with FLOAT16 and 16b_rb10), enabling cost-effective datapath resilience",
      "role": "Evidence",
      "parents": [
        15
      ],
      "children": null
    }
  ]
}